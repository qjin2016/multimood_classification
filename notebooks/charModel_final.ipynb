{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used for developing charCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D, BatchNormalization\n",
    "from keras.layers import LSTM, Lambda, concatenate\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import keras.callbacks\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3561, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "empathies = pd.read_csv('./empathies.csv')\n",
    "msg = pd.read_csv('./msg_fasttext.csv')\n",
    "msg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "msg = msg.drop(msg.columns[0:2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a set of all the characters in the data\n",
    "char_set = set()\n",
    "for ms in msg['message']:\n",
    "    for ch in ms:\n",
    "        char_set.add(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a map of character and its corresponding index\n",
    "char_indices = dict((c, i) for i, c in enumerate(char_set))\n",
    "indices_char = dict((i, c) for i, c in enumerate(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding of labels\n",
    "sentiments = np.zeros((msg.shape[0], empathies.shape[0]), dtype = np.int64)\n",
    "i = 0\n",
    "for emps in msg['empathy']:\n",
    "    for emp in emps.split(','):\n",
    "        emp = emp.strip()\n",
    "        try:\n",
    "            idx = empathies[empathies['empathy'] == emp].index[0]\n",
    "            sentiments[i][idx] = 1\n",
    "        except:\n",
    "            print(emp)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique characters\n",
    "len(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = sentiments.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform original data into character index format\n",
    "max_len = 100\n",
    "X = np.zeros((msg.shape[0], max_len), dtype=np.int64)\n",
    "\n",
    "for i, sen in enumerate(msg['message']):\n",
    "    for j, ch in enumerate(sen):\n",
    "        if j < max_len:\n",
    "            X[i, max_len-1-j] = char_indices[ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and validation data\n",
    "X_train = X[:2500]\n",
    "X_test = X[2500:]\n",
    "\n",
    "y_train = y[:2500]\n",
    "y_test = y[2500:]\n",
    "\n",
    "# dimension of character embedding\n",
    "char_embedding = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used for embedding layer\n",
    "def binarize(x, sz=100):\n",
    "    '''\n",
    "    sz: embedding size\n",
    "    '''\n",
    "    import tensorflow as tf\n",
    "    return tf.to_float(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1))\n",
    "\n",
    "\n",
    "def binarize_outshape(in_shape):\n",
    "    return in_shape[0], in_shape[1], 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char_block(in_layer, nb_filter=(64, 100), filter_length=(3, 3), subsample=(2, 1), pool_length=(2, 2)):\n",
    "    block = in_layer\n",
    "    for i in range(len(nb_filter)):\n",
    "\n",
    "        block = Conv1D(filters=nb_filter[i],\n",
    "                       kernel_size=filter_length[i],\n",
    "                       padding='valid',\n",
    "                       activation='tanh',\n",
    "                       strides=subsample[i])(block)\n",
    "\n",
    "#         block = BatchNormalization()(block)\n",
    "#         block = Dropout(0.2)(block)\n",
    "        if pool_length[i]:\n",
    "            block = MaxPooling1D(pool_size=pool_length[i])(block)\n",
    "\n",
    "    # block = Lambda(max_1d, output_shape=(nb_filter[-1],))(block)\n",
    "    block = GlobalMaxPool1D()(block)\n",
    "    block = Dense(128, activation='relu')(block)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = len(char_set) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_sentence = Input(shape=(max_len,), dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedded = Lambda(binarize, output_shape=binarize_outshape)(in_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "block2 = char_block(embedded, (128, 256), filter_length=(5, 5), subsample=(1, 1), pool_length=(2, 2))\n",
    "block3 = char_block(embedded, (192, 320), filter_length=(7, 5), subsample=(1, 1), pool_length=(2, 2))\n",
    "\n",
    "sent_encode = concatenate([block2, block3], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = Dense(64, activation='softmax')(sent_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 100, 100)      0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 96, 128)       64128       lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                (None, 94, 192)       134592      lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)   (None, 48, 128)       0           conv1d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)   (None, 47, 192)       0           conv1d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, 44, 256)       164096      max_pooling1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 43, 320)       307520      max_pooling1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)   (None, 22, 256)       0           conv1d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)   (None, 21, 320)       0           conv1d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalMa (None, 256)           0           max_pooling1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalMa (None, 320)           0           max_pooling1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           32896       global_max_pooling1d_1[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           41088       global_max_pooling1d_2[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           dense_1[0][0]                    \n",
      "                                                                   dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            16448       concatenate_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 760,768\n",
      "Trainable params: 760,768\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=in_sentence, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlystop_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "optimizer = 'adam'\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 1061 samples\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 19s - loss: 5.2398 - acc: 0.0544 - val_loss: 5.0655 - val_acc: 0.0980\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 20s - loss: 4.8687 - acc: 0.1176 - val_loss: 4.8383 - val_acc: 0.1527\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 20s - loss: 4.6107 - acc: 0.1752 - val_loss: 4.5981 - val_acc: 0.1932\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 22s - loss: 4.3243 - acc: 0.2384 - val_loss: 4.3504 - val_acc: 0.2762\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 22s - loss: 4.0350 - acc: 0.3188 - val_loss: 4.1267 - val_acc: 0.3186\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 24s - loss: 3.7449 - acc: 0.3592 - val_loss: 3.9239 - val_acc: 0.3516\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 26s - loss: 3.4692 - acc: 0.4224 - val_loss: 3.7656 - val_acc: 0.3657\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 25s - loss: 3.1837 - acc: 0.4712 - val_loss: 3.6141 - val_acc: 0.3845\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 26s - loss: 2.9127 - acc: 0.5084 - val_loss: 3.4631 - val_acc: 0.4119\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 24s - loss: 2.6611 - acc: 0.5432 - val_loss: 3.3984 - val_acc: 0.4232\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 20s - loss: 2.4283 - acc: 0.5788 - val_loss: 3.2685 - val_acc: 0.4270\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 19s - loss: 2.1734 - acc: 0.6176 - val_loss: 3.2173 - val_acc: 0.4430\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 21s - loss: 1.9574 - acc: 0.6504 - val_loss: 3.1769 - val_acc: 0.4571\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 25s - loss: 1.7623 - acc: 0.6848 - val_loss: 3.1136 - val_acc: 0.4599\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 26s - loss: 1.5743 - acc: 0.7148 - val_loss: 3.0802 - val_acc: 0.4713\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 20s - loss: 1.4048 - acc: 0.7428 - val_loss: 3.0552 - val_acc: 0.4722\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 20s - loss: 1.2697 - acc: 0.7548 - val_loss: 3.0631 - val_acc: 0.4694\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 18s - loss: 1.1496 - acc: 0.7768 - val_loss: 3.0464 - val_acc: 0.4863\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 25s - loss: 1.0412 - acc: 0.8008 - val_loss: 3.0236 - val_acc: 0.4779\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 21s - loss: 0.9575 - acc: 0.8084 - val_loss: 3.0393 - val_acc: 0.4835\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 20s - loss: 0.8876 - acc: 0.8124 - val_loss: 3.0651 - val_acc: 0.4901\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 21s - loss: 0.8339 - acc: 0.8220 - val_loss: 3.0980 - val_acc: 0.4854\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 22s - loss: 0.7972 - acc: 0.8276 - val_loss: 3.0684 - val_acc: 0.4901\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 20s - loss: 0.7648 - acc: 0.8300 - val_loss: 3.1329 - val_acc: 0.4901\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 20s - loss: 0.7419 - acc: 0.8300 - val_loss: 3.1266 - val_acc: 0.4948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10b999ba8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=256, epochs=30, \n",
    "          shuffle=True, callbacks=[earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.save('./charModel_final.h5')\n",
    "# model = load_model('./charModel_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (relaxed, nonrelaxed & bar-chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a map that contains empathy and its corresponding polarity score, this map will be used to compute metrics\n",
    "dict_polarities = {}\n",
    "for i in range(empathies.shape[0]):\n",
    "    dict_polarities[empathies.iloc[i][0]] = float(empathies.iloc[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to compare against the ground truth in a **relaxed**  format, which means if the predicted class is not exactly the same as the truth, but has the same polarity score. The prediction will still be counted as truth positive\n",
    "\n",
    "The output is a dictionary contained label: number of true positives, false positives and false negatives\n",
    "the output will be used for calculating overall precision, recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_truth_relaxed(cutoff_value, dict_polarities, model, inputs, all_preds, start, stop):\n",
    "    '''\n",
    "    output: {label: [TP, FP, FN]}\n",
    "    '''\n",
    "    label_s = list(dict_polarities.keys())\n",
    "    res = {}\n",
    "    \n",
    "    for l in label_s:\n",
    "        # True Positives, False Positives, False Negatives\n",
    "        res[l] = [0, 0, 0]\n",
    "    \n",
    "    j = -1\n",
    "    for i in range(start, stop):\n",
    "        j += 1\n",
    "        preds = all_preds[j]\n",
    "        true_scores = [dict_polarities[la.strip()] for la in msg.iloc[i]['empathy'].split(',') if la != '']\n",
    "        \n",
    "        # store predicted labels and the corresponding polarity score\n",
    "        pred_labs, scores  = [], []\n",
    "        preds = [list(empathies['empathy'][np.argsort(preds)[63:58:-1]]), np.sort(preds)[63:58:-1]]\n",
    "        \n",
    "        idx = 0\n",
    "        for lab, p in zip(preds[0], preds[1]):\n",
    "            idx += 1\n",
    "            if p > cutoff_value or idx == 1:\n",
    "                pred_labs.append(lab)\n",
    "                scores.append(dict_polarities[lab])\n",
    "                if lab in msg.iloc[i]['empathy'] or dict_polarities[lab] in true_scores:\n",
    "                    # true positive\n",
    "                    res[lab][0] += 1\n",
    "                if lab not in msg.iloc[i]['empathy'] and dict_polarities[lab] not in true_scores:\n",
    "                    # false positive\n",
    "                    res[lab][1] += 1\n",
    "                \n",
    "        for true_lab in msg.iloc[i]['empathy'].split(','):\n",
    "            true_lab = true_lab.strip()\n",
    "            if true_lab != '' and true_lab != ' ' and true_lab not in pred_labs and dict_polarities[lab] not in scores:\n",
    "                # false negative\n",
    "                res[true_lab][2] += 1\n",
    "                \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiar as the above function. The following function is used to compare against the ground truth, but in a **nonrelaxed** format -- the predicted class has to be exactly the same as the truth in order to be counted as true positive.\n",
    "\n",
    "The output is a dictionary contained label: number of true positives, false positives and false negatives\n",
    "the output will be used for calculating overall precision, recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_truth_nonrelaxed(cutoff_value, dict_polarities, model, inputs, all_preds, start, stop):\n",
    "    '''\n",
    "    output: {label: [TP, FP, FN]}\n",
    "    '''\n",
    "    label_s = list(dict_polarities.keys())\n",
    "    res = {}\n",
    "    \n",
    "    for l in label_s:\n",
    "        # True Positives, False Positives, False Negatives\n",
    "        res[l] = [0, 0, 0]\n",
    "    \n",
    "    j = -1\n",
    "    for i in range(start, stop):\n",
    "        j += 1\n",
    "        preds = all_preds[j]\n",
    "        true_scores = [dict_polarities[la.strip()] for la in msg.iloc[i]['empathy'].split(',') if la != '']\n",
    "        \n",
    "        # store predicted labels and the corresponding polarity score\n",
    "        pred_labs, scores  = [], []\n",
    "        preds = [list(empathies['empathy'][np.argsort(preds)[63:58:-1]]), np.sort(preds)[63:58:-1]]\n",
    "        \n",
    "        for lab, p in zip(preds[0], preds[1]):\n",
    "            if p > cutoff_value:\n",
    "                pred_labs.append(lab)\n",
    "                scores.append(dict_polarities[lab])\n",
    "                print(lab)\n",
    "                if lab in msg.iloc[i]['empathy']:\n",
    "                    # true positive\n",
    "                    res[lab][0] += 1\n",
    "                if lab not in msg.iloc[i]['empathy']:\n",
    "                    # false positive\n",
    "                    res[lab][1] += 1\n",
    "                \n",
    "        for true_lab in msg.iloc[i]['empathy'].split(','):\n",
    "            true_lab = true_lab.strip()\n",
    "            if true_lab != '' and true_lab != ' ' and true_lab not in pred_labs:\n",
    "                # false negative\n",
    "                res[true_lab][2] += 1\n",
    "                \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overall_score(res):\n",
    "    '''\n",
    "    output precision, recall and F1 score\n",
    "    '''\n",
    "    num_TP, num_FP, num_FN = 0, 0, 0\n",
    "    \n",
    "    for _, vals in res.items():\n",
    "        num_TP += vals[0]\n",
    "        num_FP += vals[1]\n",
    "        num_FN += vals[2]\n",
    "            \n",
    "    precision = num_TP/(num_TP+num_FP)\n",
    "    recall = num_TP/(num_TP+num_FN)\n",
    "    \n",
    "    return precision, recall, 2/(1/precision + 1/recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# explore the best cutoff value with the training data\n",
    "ps, rs, fs = [], [], []\n",
    "for proposed_cut in np.arange(.0, .6, .1):\n",
    "    res = compare_truth_relaxed(proposed_cut, dict_polarities, model, msg, train_preds, 0, 2500)\n",
    "    p, r, f = overall_score(res)\n",
    "    ps.append(p)\n",
    "    rs.append(rs)\n",
    "    fs.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJX4RkQKjxC8iUmCU+EVECsz/A4ZkkOgTO+b8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12411fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the change of F1 score as the cutoff value increases from 0.0 to 0.6\n",
    "proposed_cuts = np.arange(.0, .6, .1)\n",
    "# red dashes\n",
    "plt.plot(proposed_cuts, fs, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20000000000000001"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fs_idx = fs.index(max(fs))\n",
    "np.arange(.0, .6, .1)[max_fs_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confu_plot(con_matrix):\n",
    "    '''\n",
    "    generate bar-chart of true positives, false positives and false negatives for each class\n",
    "    '''\n",
    "    names = []\n",
    "    TP, FP, FN = [], [], []\n",
    "    for k, vals in con_matrix.items():\n",
    "        name=k.replace('__label__', '')\n",
    "        names.append(name)\n",
    "        TP.append(vals[0])\n",
    "        FP.append(vals[1])\n",
    "        FN.append(vals[2])\n",
    "\n",
    "    trace1 = go.Bar(\n",
    "        x=names,\n",
    "        y=TP,\n",
    "        name='True Positive'\n",
    "    )\n",
    "\n",
    "    trace2 = go.Bar(\n",
    "        x=names,\n",
    "        y=FP,\n",
    "        name='False Positive'\n",
    "    )\n",
    "\n",
    "    trace3 = go.Bar(\n",
    "        x=names,\n",
    "        y=FN,\n",
    "        name='False Negative'\n",
    "    )\n",
    "\n",
    "    data = [trace1, trace2, trace3]\n",
    "    layout = go.Layout(\n",
    "        barmode='group',\n",
    "\n",
    "        xaxis=dict(\n",
    "            title='labels',\n",
    "            titlefont=dict(\n",
    "                size=18,\n",
    "            ),\n",
    "            showticklabels=True,\n",
    "            tickangle=45,\n",
    "            tickfont=dict(\n",
    "                size=14,\n",
    "                color='black'\n",
    "            ),\n",
    "            exponentformat='e',\n",
    "            showexponent='All'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    plotly.offline.iplot(fig, filename='grouped-bar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = compare_truth_relaxed(.2, dict_polarities, model, msg, test_preds, 2500, msg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6674509803921569, 0.6135544340302812, 0.6393688955672427)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_score(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"56d37d34-f971-4084-a63b-eba0a49fd88f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"56d37d34-f971-4084-a63b-eba0a49fd88f\", [{\"name\": \"True Positive\", \"y\": [13, 2, 29, 11, 58, 17, 1, 1, 0, 1, 25, 7, 40, 18, 17, 24, 5, 19, 7, 24, 0, 10, 40, 2, 0, 12, 0, 3, 1, 9, 8, 0, 2, 12, 1, 3, 56, 9, 0, 48, 0, 47, 11, 0, 0, 7, 3, 2, 39, 0, 30, 2, 21, 10, 2, 1, 9, 4, 0, 3, 67, 32, 20, 6], \"type\": \"bar\", \"x\": [\"idk\", \"intoxicated\", \"annoyed\", \"hungry\", \"sad\", \"average\", \"jealous\", \"affectionate\", \"playful\", \"embarrassed\", \"emotionless\", \"scared\", \"anxious\", \"unmotivated\", \"determined\", \"stress\", \"lazy\", \"better\", \"pensive\", \"okay\", \"thirsty\", \"stable\", \"excited\", \"restless\", \"panic\", \"distortion\", \"regret\", \"relief\", \"upset\", \"uneasy\", \"disconnected\", \"sexy\", \"flustered\", \"confidence\", \"loved\", \"inspired\", \"tired\", \"confused\", \"rude\", \"calm\", \"creative\", \"depressed\", \"unsatisfied\", \"frustrated\", \"healthy\", \"loss\", \"full\", \"vulnerable\", \"sleep\", \"ignored\", \"lonely\", \"uncertain\", \"pain\", \"great\", \"despair\", \"hopeful\", \"good\", \"sick\", \"surprised\", \"emotional\", \"happy\", \"bored\", \"angry\", \"engaged\"]}, {\"name\": \"False Positive\", \"y\": [9, 3, 22, 0, 48, 19, 0, 2, 0, 0, 21, 3, 9, 10, 3, 8, 0, 14, 6, 20, 0, 7, 4, 0, 0, 7, 1, 1, 2, 6, 22, 2, 2, 5, 0, 2, 17, 16, 0, 30, 0, 9, 10, 0, 0, 2, 1, 2, 2, 0, 9, 3, 10, 6, 2, 0, 10, 2, 0, 1, 21, 5, 8, 0], \"type\": \"bar\", \"x\": [\"idk\", \"intoxicated\", \"annoyed\", \"hungry\", \"sad\", \"average\", \"jealous\", \"affectionate\", \"playful\", \"embarrassed\", \"emotionless\", \"scared\", \"anxious\", \"unmotivated\", \"determined\", \"stress\", \"lazy\", \"better\", \"pensive\", \"okay\", \"thirsty\", \"stable\", \"excited\", \"restless\", \"panic\", \"distortion\", \"regret\", \"relief\", \"upset\", \"uneasy\", \"disconnected\", \"sexy\", \"flustered\", \"confidence\", \"loved\", \"inspired\", \"tired\", \"confused\", \"rude\", \"calm\", \"creative\", \"depressed\", \"unsatisfied\", \"frustrated\", \"healthy\", \"loss\", \"full\", \"vulnerable\", \"sleep\", \"ignored\", \"lonely\", \"uncertain\", \"pain\", \"great\", \"despair\", \"hopeful\", \"good\", \"sick\", \"surprised\", \"emotional\", \"happy\", \"bored\", \"angry\", \"engaged\"]}, {\"name\": \"False Negative\", \"y\": [8, 9, 7, 0, 35, 16, 0, 7, 1, 10, 13, 8, 15, 8, 10, 9, 11, 2, 8, 21, 0, 3, 8, 2, 0, 14, 8, 11, 11, 10, 23, 5, 2, 9, 1, 1, 18, 19, 0, 20, 2, 6, 4, 0, 0, 8, 7, 9, 6, 2, 6, 7, 21, 6, 8, 2, 9, 9, 1, 5, 17, 8, 21, 9], \"type\": \"bar\", \"x\": [\"idk\", \"intoxicated\", \"annoyed\", \"hungry\", \"sad\", \"average\", \"jealous\", \"affectionate\", \"playful\", \"embarrassed\", \"emotionless\", \"scared\", \"anxious\", \"unmotivated\", \"determined\", \"stress\", \"lazy\", \"better\", \"pensive\", \"okay\", \"thirsty\", \"stable\", \"excited\", \"restless\", \"panic\", \"distortion\", \"regret\", \"relief\", \"upset\", \"uneasy\", \"disconnected\", \"sexy\", \"flustered\", \"confidence\", \"loved\", \"inspired\", \"tired\", \"confused\", \"rude\", \"calm\", \"creative\", \"depressed\", \"unsatisfied\", \"frustrated\", \"healthy\", \"loss\", \"full\", \"vulnerable\", \"sleep\", \"ignored\", \"lonely\", \"uncertain\", \"pain\", \"great\", \"despair\", \"hopeful\", \"good\", \"sick\", \"surprised\", \"emotional\", \"happy\", \"bored\", \"angry\", \"engaged\"]}], {\"barmode\": \"group\", \"xaxis\": {\"tickfont\": {\"color\": \"black\", \"size\": 14}, \"title\": \"labels\", \"showexponent\": \"All\", \"tickangle\": 45, \"showticklabels\": true, \"titlefont\": {\"size\": 18}, \"exponentformat\": \"e\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confu_plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used for transform a string into the acceptable format for the model\n",
    "def text_processor(input_str, char_indices, max_len = 100):\n",
    "    '''\n",
    "    ---\n",
    "    args:\n",
    "        input_str: an input string\n",
    "        char_indices: map of character index calculated from above\n",
    "        max_len: the length of input that the model accepts\n",
    "    ---\n",
    "    return:\n",
    "       padded sequence for the model \n",
    "    '''\n",
    "    sen2input = np.zeros((1, max_len), dtype=np.int64)\n",
    "    \n",
    "    for j, ch in enumerate(input_str):\n",
    "        if j < max_len:\n",
    "            sen2input[0, max_len-1-j] = char_indices[ch]\n",
    "    \n",
    "    return sen2input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hungry', 'angry', 'annoyed', 'sad', 'uneasy'],\n",
       " array([ 0.68242598,  0.26267356,  0.01349587,  0.0098852 ,  0.00448579], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_input = text_processor('huuungry', char_indices)\n",
    "random_pred = model.predict(random_input)\n",
    "[list(empathies['empathy'][np.argsort(random_pred)[0][63:58:-1]]), np.sort(random_pred)[0][63:58:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
